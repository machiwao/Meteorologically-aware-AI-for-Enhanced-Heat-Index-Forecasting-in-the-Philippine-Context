{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KaGjnF7aDVRz",
        "outputId": "914251be-6735-41e4-f37b-a865a2d15ad6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import re\n",
        "import pandas as pd\n",
        "from scipy.signal import savgol_filter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cloud_project = 'heat-index-forecasting'\n",
        "\n",
        "try:\n",
        "  ee.Initialize(project=cloud_project)\n",
        "except:\n",
        "  ee.Authenticate()\n",
        "  ee.Initialize(project=cloud_project)\n",
        "\n",
        "stations = {\n",
        "  \"Sinait\": ee.Geometry.Point([120.459762, 17.89019]).buffer(5000),\n",
        "  \"Tayabas\": ee.Geometry.Point([121.596575, 14.018428]).buffer(5000),\n",
        "  \"Tanay\": ee.Geometry.Point([121.36927, 14.581167]).buffer(5000),\n",
        "  \"Tuguegarao\": ee.Geometry.Point([121.758469, 17.647678]).buffer(5000),\n",
        "  \"Virac\": ee.Geometry.Point([124.209834, 13.576558]).buffer(5000),\n",
        "  \"Calapan\": ee.Geometry.Point([121.1896667, 13.409775]).buffer(5000),\n",
        "  \"CLSU\": ee.Geometry.Point([120.9368, 15.73586]).buffer(5000),\n",
        "  \"Clark\": ee.Geometry.Point([120.5616667, 15.1717]).buffer(5000),\n",
        "  \"Daet\": ee.Geometry.Point([122.982559, 14.128689]).buffer(5000),\n",
        "  \"Dagupan\": ee.Geometry.Point([120.352045, 16.086784]).buffer(5000)\n",
        "}\n",
        "\n",
        "start_date = \"2014-01-01\"\n",
        "end_date   = \"2024-01-01\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KVzZm8gtDc4g",
        "outputId": "d83d54e9-322c-48da-98b9-51d677b13b9d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_process_era5(point, dataset, start_date, end_date, station_name, chunk_size=5):\n",
        "    \"\"\"\n",
        "    Extracts and processes ERA5-Land daily aggregated data for a given point,\n",
        "    filtered by date and spatial extent, with memory-safe chunked aggregation.\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Filter dataset by date and region before extraction\n",
        "    dataset_filtered = dataset.filterDate(start_date, end_date).filterBounds(point)\n",
        "\n",
        "    def extract(img):\n",
        "        vals = img.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=point,\n",
        "            scale=11132,      # ERA5-Land native resolution (~11 km)\n",
        "            maxPixels=1e13,\n",
        "            bestEffort=True\n",
        "        )\n",
        "        return ee.Feature(None, vals).set(\"date\", img.date().format(\"YYYY-MM-dd\"))\n",
        "\n",
        "    fc = dataset_filtered.map(extract)\n",
        "\n",
        "    # Get variable names\n",
        "    var_names = dataset_filtered.first().bandNames().getInfo()\n",
        "\n",
        "    # --- Memory-safe chunked aggregation ---\n",
        "    def safe_extract(fc, var_names, chunk_size=5):\n",
        "        data_dict = {'date': fc.aggregate_array('date').getInfo()}\n",
        "        for i in range(0, len(var_names), chunk_size):\n",
        "            subset = var_names[i:i + chunk_size]\n",
        "            try:\n",
        "                subset_dict = ee.Dictionary.fromLists(\n",
        "                    subset, [fc.aggregate_array(v) for v in subset]\n",
        "                ).getInfo()\n",
        "                data_dict.update(subset_dict)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Skipping bands {subset} due to memory issue: {e}\")\n",
        "        # Pad shorter lists with None\n",
        "        max_len = len(data_dict['date'])\n",
        "        for k, v in data_dict.items():\n",
        "            if len(v) < max_len:\n",
        "                data_dict[k] = v + [None] * (max_len - len(v))\n",
        "        return data_dict\n",
        "\n",
        "    data_dict = safe_extract(fc, var_names, chunk_size)\n",
        "\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "    # --- Conversion rules ---\n",
        "    UNIT_CONVERSIONS = [\n",
        "        (r\"temperature\", lambda x: x - 273.15, \"K\", \"°C\", \"_C\"),\n",
        "        (r\"pressure\", lambda x: x / 100, \"Pa\", \"hPa\", \"_hPa\"),\n",
        "        (r\"(u_component|v_component|wind)\", lambda x: x * 3.6, \"m/s\", \"km/h\", \"_kmh\"),\n",
        "        (r\"snow_depth\", lambda x: x * 100, \"m\", \"cm\", \"_cm\"),\n",
        "        (r\"(sum|precipitation|evaporation|runoff)(_min|_max)?\", lambda x: x * 1000, \"m\", \"mm/day\", \"_mm\"),\n",
        "        (r\"(radiation_sum|flux_sum|heat_sum)(_min|_max)?\", lambda x: x / 86400, \"J/m²/day\", \"W/m²\", \"_Wm2\")\n",
        "    ]\n",
        "\n",
        "    rename_map = {}\n",
        "    metadata = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col == \"date\" or df[col].isnull().all():\n",
        "            continue\n",
        "        for pattern, func, orig_unit, conv_unit, suffix in UNIT_CONVERSIONS:\n",
        "            if re.search(pattern, col.lower()):\n",
        "                df[col] = func(df[col])\n",
        "                new_col = col + suffix\n",
        "                rename_map[col] = new_col\n",
        "                metadata.append({\n",
        "                    \"Band\": col,\n",
        "                    \"Converted Column\": new_col,\n",
        "                    \"Original Unit\": orig_unit,\n",
        "                    \"Converted Unit\": conv_unit\n",
        "                })\n",
        "                break\n",
        "\n",
        "    if rename_map:\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "    # Save the processed DataFrame to CSV\n",
        "    out_file = f\"{station_name}_ERA5.csv\"\n",
        "    df.to_csv(out_file, index=False)\n",
        "\n",
        "    print(f\"Saved {out_file} ({df.shape[0]} rows)\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "av53QmLXE5Gc",
        "outputId": "3664b564-aa97-4a33-9aea-3606a0c83b21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')\n",
        "\n",
        "station_dataframes = {}\n",
        "for station_name, station_point in stations.items():\n",
        "    print(f\"Extracting and processing data for {station_name}...\")\n",
        "    try:\n",
        "        df_station = extract_and_process_era5(station_point, dataset, start_date, end_date, station_name)\n",
        "        station_dataframes[station_name] = df_station\n",
        "        print(f\"Successfully extracted and processed data for {station_name}.\")\n",
        "        print(f\"DataFrame shape: {df_station.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing data for {station_name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "Y0tZL5tVNlNA",
        "outputId": "cf7dadfb-98e5-4469-9d00-1310f8a4e4b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting and processing data for Sinait...\n",
            "Saved Sinait_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Sinait.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Tayabas...\n",
            "Saved Tayabas_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Tayabas.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Tanay...\n",
            "Saved Tanay_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Tanay.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Tuguegarao...\n",
            "Saved Tuguegarao_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Tuguegarao.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Virac...\n",
            "Saved Virac_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Virac.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Calapan...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Sleeping 1.43 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/heat-index-forecasting/value:compute?prettyPrint=false&alt=json, after 503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Calapan_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Calapan.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for CLSU...\n",
            "Saved CLSU_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for CLSU.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Clark...\n",
            "Saved Clark_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Clark.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Daet...\n",
            "Saved Daet_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Daet.\n",
            "DataFrame shape: (3652, 151)\n",
            "Extracting and processing data for Dagupan...\n",
            "Saved Dagupan_ERA5.csv (3652 rows)\n",
            "Successfully extracted and processed data for Dagupan.\n",
            "DataFrame shape: (3652, 151)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the base path in Google Drive\n",
        "# drive_base_path = '/content/drive/MyDrive/ERA5Datasets'\n",
        "\n",
        "# # Ensure the directory exists, create if not\n",
        "# if not os.path.exists(drive_base_path):\n",
        "#     try:\n",
        "#         os.makedirs(drive_base_path)\n",
        "#         print(f\"Created directory: {drive_base_path}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error creating directory {drive_base_path}: {e}\")\n",
        "#         # If directory creation fails, proceed with local save only\n",
        "\n",
        "# # Iterate through the station_dataframes dictionary and save each DataFrame\n",
        "# for station_name, df_station in station_dataframes.items():\n",
        "#     # Construct the filename\n",
        "#     filename = f\"{station_name.replace(' ', '_')}_ERA5_Data.csv\"\n",
        "#     drive_path = os.path.join(drive_base_path, filename)\n",
        "\n",
        "#     try:\n",
        "#         # Save to Google Drive\n",
        "#         df_station.to_csv(drive_path, index=False)\n",
        "#         print(f\"File saved to Google Drive: {drive_path}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error saving file to Google Drive for {station_name}: {e}\")\n",
        "#         # Save locally as backup if Drive save fails\n",
        "#         local_path = filename\n",
        "#         df_station.to_csv(local_path, index=False)\n",
        "#         print(f\"File saved locally as backup: {local_path}\")"
      ],
      "metadata": {
        "id": "7HPBJGaMNwBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6b8d5f14-cd26-4bee-abc0-54bc0375c2f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}