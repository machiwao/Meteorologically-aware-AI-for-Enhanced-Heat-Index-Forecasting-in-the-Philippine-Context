{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3e1377",
   "metadata": {},
   "source": [
    "# XGBoost Multi-Output Regression with Nested CV\n",
    "This notebook trains a global XGBoost model to predict **HI, TMAX, RH** using multi-output regression with **nested cross-validation**, chronological splits, and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Ensure output folders\n",
    "os.makedirs(\"models\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4250d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all station CSVs from merged_datasets folder\n",
    "folder = \"merged_datasets\"\n",
    "all_data = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        station = file.replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(folder, file))\n",
    "        df[\"Station\"] = station\n",
    "        all_data.append(df)\n",
    "\n",
    "data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(\"Shape:\", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "target_cols = [\"HI\", \"TMAX\", \"RH\"]\n",
    "feature_cols = [c for c in data.columns if c not in target_cols + [\"Station\", \"YEAR\", \"MONTH\", \"DAY\"]]\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_cols]\n",
    "stations = data[\"Station\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronological 80-10-10 split\n",
    "n = len(data)\n",
    "train_end = int(n * 0.8)\n",
    "val_end = int(n * 0.9)\n",
    "\n",
    "X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
    "X_val, y_val = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n",
    "X_test, y_test = X.iloc[val_end:], y.iloc[val_end:]\n",
    "stations_val = stations.iloc[train_end:val_end]\n",
    "stations_test = stations.iloc[val_end:]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27088358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base estimator\n",
    "xgb_est = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "multi_est = MultiOutputRegressor(xgb_est)\n",
    "\n",
    "# Hyperparameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"estimator__n_estimators\": [200, 500, 1000],\n",
    "    \"estimator__learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"estimator__max_depth\": [3, 5, 7],\n",
    "    \"estimator__subsample\": [0.7, 0.8, 1.0],\n",
    "    \"estimator__colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Inner CV\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=multi_est,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = search.best_params_\n",
    "best_est = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    **{k.replace(\"estimator__\", \"\"): v for k,v in best_params.items()}\n",
    ")\n",
    "\n",
    "final_model = MultiOutputRegressor(best_est)\n",
    "\n",
    "# Use validation set for early stopping\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    **{\"estimator__eval_set\":[(X_val, y_val)], \"estimator__early_stopping_rounds\":20, \"estimator__verbose\":False}\n",
    ")\n",
    "\n",
    "# Save model\n",
    "final_model.estimators_[0].save_model(\"models/xgb_model.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, stations_subset):\n",
    "    results = []\n",
    "    for st in stations_subset.unique():\n",
    "        idx = stations_subset == st\n",
    "        rmse = np.sqrt(mean_squared_error(y_true[idx], y_pred[idx]))\n",
    "        r2 = r2_score(y_true[idx], y_pred[idx])\n",
    "        results.append({\"Station\": st, \"RMSE\": rmse, \"R2\": r2})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Validation results\n",
    "val_pred = final_model.predict(X_val)\n",
    "df_val_metrics = evaluate_predictions(y_val, val_pred, stations_val)\n",
    "\n",
    "# Test results\n",
    "test_pred = final_model.predict(X_test)\n",
    "df_test_metrics = evaluate_predictions(y_test, test_pred, stations_test)\n",
    "\n",
    "print(\"Validation Metrics:\")\n",
    "display(df_val_metrics)\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "display(df_test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted per station (test set)\n",
    "for st in stations_test.unique():\n",
    "    idx = stations_test == st\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(y_test[idx].values[:,0], label=\"Actual HI\")\n",
    "    plt.plot(test_pred[idx][:,0], label=\"Pred HI\")\n",
    "    plt.title(f\"Station {st} - HI Prediction (Test)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92896207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- AUTO-ADDED: Forecast HI for t+1 and t+2, display metrics as tables ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, sys\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    has_xgb = True\n",
    "except Exception as e:\n",
    "    XGBRegressor = None\n",
    "    has_xgb = False\n",
    "\n",
    "# 1) Get df\n",
    "try:\n",
    "    df\n",
    "    print(\"Using existing DataFrame `df` from the notebook kernel.\")\n",
    "except NameError:\n",
    "    raise RuntimeError(\"No DataFrame `df` present. Please run the notebook's data-loading cells first.\")\n",
    "\n",
    "# 2) Identify station and datetime columns\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "def find_column(candidates):\n",
    "    for cand in candidates:\n",
    "        for c in cols:\n",
    "            if cand.lower() == c.lower():\n",
    "                return c\n",
    "    for cand in candidates:\n",
    "        for c in cols:\n",
    "            if cand.lower() in c.lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "station_col = find_column(['station','station_id','stn','site','stationid','station_code'])\n",
    "datetime_col = find_column(['datetime','date','time','timestamp','obs_time','datetime_utc'])\n",
    "\n",
    "if station_col is None:\n",
    "    raise RuntimeError(\"Could not detect a station column. Columns found: \" + \", \".join(cols))\n",
    "\n",
    "if datetime_col is not None:\n",
    "    try:\n",
    "        df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 3) Find HI column\n",
    "hi_col = find_column(['HI','heat_index','heat index','heatindex','hi'])\n",
    "if hi_col is None:\n",
    "    raise RuntimeError(\"Could not detect a Heat Index (HI) column. Columns found: \" + \", \".join(cols))\n",
    "\n",
    "print(f\"Detected station column: {station_col}, datetime: {datetime_col}, HI column: {hi_col}\")\n",
    "\n",
    "# sort by station and datetime if available\n",
    "if datetime_col is not None:\n",
    "    df = df.sort_values(by=[station_col, datetime_col]).reset_index(drop=True)\n",
    "else:\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "# create targets\n",
    "df['HI_t+1'] = df.groupby(station_col)[hi_col].shift(-1)\n",
    "df['HI_t+2'] = df.groupby(station_col)[hi_col].shift(-2)\n",
    "df_targets = df.dropna(subset=['HI_t+1','HI_t+2'], how='all').copy()\n",
    "\n",
    "# feature selection\n",
    "exclude = {station_col, datetime_col, hi_col, 'HI_t+1', 'HI_t+2'}\n",
    "features = [c for c in df_targets.columns if c not in exclude and pd.api.types.is_numeric_dtype(df_targets[c])]\n",
    "if not features:\n",
    "    features = [hi_col]\n",
    "print(f\"Using features: {features}\")\n",
    "\n",
    "# evaluation loop\n",
    "def compute_metrics_for_horizon(horizon_col):\n",
    "    stations = df_targets[station_col].unique().tolist()\n",
    "    results = []\n",
    "    all_y_true, all_y_pred = [], []\n",
    "    for st in stations:\n",
    "        train = df_targets[df_targets[station_col] != st].dropna(subset=features + [horizon_col])\n",
    "        test = df_targets[df_targets[station_col] == st].dropna(subset=features + [horizon_col])\n",
    "        if train.empty or test.empty:\n",
    "            continue\n",
    "        X_train, y_train = train[features].values, train[horizon_col].values\n",
    "        X_test, y_test = test[features].values, test[horizon_col].values\n",
    "        if has_xgb:\n",
    "            model = XGBRegressor(n_estimators=100, max_depth=6, random_state=42, verbosity=0)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        results.append({'station': st, 'n_test': len(y_test), 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        all_y_true.extend(y_test.tolist())\n",
    "        all_y_pred.extend(y_pred.tolist())\n",
    "    if all_y_true:\n",
    "        overall = {\n",
    "            'station': 'ALL',\n",
    "            'n_test': len(all_y_true),\n",
    "            'MAE': mean_absolute_error(all_y_true, all_y_pred),\n",
    "            'RMSE': mean_squared_error(all_y_true, all_y_pred, squared=False),\n",
    "            'R2': r2_score(all_y_true, all_y_pred)\n",
    "        }\n",
    "        results.append(overall)\n",
    "    return pd.DataFrame(results).sort_values(by='station').reset_index(drop=True)\n",
    "\n",
    "metrics_t1 = compute_metrics_for_horizon('HI_t+1')\n",
    "metrics_t2 = compute_metrics_for_horizon('HI_t+2')\n",
    "\n",
    "print(\"\\\\n=== Metrics for HI_t+1 (tomorrow) ===\")\n",
    "display(metrics_t1)\n",
    "print(\"\\\\n=== Metrics for HI_t+2 (day after tomorrow) ===\")\n",
    "display(metrics_t2)\n",
    "\n",
    "general_metrics = pd.DataFrame([\n",
    "    {'horizon':'t+1', **metrics_t1[metrics_t1['station']=='ALL'].iloc[0].to_dict()},\n",
    "    {'horizon':'t+2', **metrics_t2[metrics_t2['station']=='ALL'].iloc[0].to_dict()}\n",
    "]).rename(columns={'n_test':'n_test_overall'})\n",
    "\n",
    "print(\"\\\\n=== General Metrics (all stations combined) ===\")\n",
    "display(general_metrics)\n",
    "\n",
    "HI_forecast_metrics = {'t+1': metrics_t1, 't+2': metrics_t2, 'general': general_metrics}\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
